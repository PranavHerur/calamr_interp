{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Embedding Space Analysis\n",
    "\n",
    "**Question:** What does the learned representation look like? Where does class separation emerge?\n",
    "\n",
    "This notebook:\n",
    "1. Extracts intermediate graph-level embeddings via forward hooks\n",
    "2. Visualizes with t-SNE and UMAP at each layer\n",
    "3. Runs linear probing to measure where separability emerges\n",
    "4. Computes CKA across layers and models\n",
    "5. Analyzes within-class vs between-class cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from calamr_interp.utils.data_loading import load_and_split\n",
    "from calamr_interp.utils.model_loading import create_model, load_model_checkpoint, find_checkpoints\n",
    "from calamr_interp.utils.visualization import setup_style, heatmap, COLORS\n",
    "from calamr_interp.phase5_embeddings import (\n",
    "    LayerEmbeddingExtractor,\n",
    "    EmbeddingVisualizer,\n",
    "    ProbingClassifier,\n",
    "    CKAAnalysis,\n",
    "    cosine_similarity_analysis,\n",
    ")\n",
    "\n",
    "setup_style()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data, val_data, test_data = load_and_split()\n",
    "test_list = list(test_data)\n",
    "test_labels = np.array([d.y.item() for d in test_list])\n",
    "print(f'Test: {len(test_list)} graphs ({sum(test_labels)} hallu, {sum(1-test_labels)} truth)')\n",
    "\n",
    "# Load model (update checkpoint path as needed)\n",
    "# model = load_model_checkpoint('path/to/best_model.pt', 'GraphTransformer', device=device)\n",
    "model = create_model('GraphTransformer')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(f'Model: {type(model).__name__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Layer Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = LayerEmbeddingExtractor(model, device)\n",
    "extractor.register_hooks()\n",
    "\n",
    "# Extract embeddings for test set\n",
    "layer_embeddings = extractor.extract_graph_embeddings(test_list)\n",
    "\n",
    "print(f'Extracted embeddings from {len(layer_embeddings)} layers:')\n",
    "for name, emb in layer_embeddings.items():\n",
    "    print(f'  {name}: shape {emb.shape}')\n",
    "\n",
    "extractor.clear_hooks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. t-SNE & UMAP Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = EmbeddingVisualizer(seed=42)\n",
    "\n",
    "# t-SNE at each layer\n",
    "n_layers = len(layer_embeddings)\n",
    "fig, axes = plt.subplots(1, min(n_layers, 4), figsize=(6*min(n_layers, 4), 5))\n",
    "if n_layers == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, (layer_name, emb) in enumerate(list(layer_embeddings.items())[:4]):\n",
    "    coords = viz.tsne(emb)\n",
    "    viz.plot_scatter(coords, test_labels, title=f't-SNE: {layer_name}', method='t-SNE', ax=axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP at each layer\n",
    "fig, axes = plt.subplots(1, min(n_layers, 4), figsize=(6*min(n_layers, 4), 5))\n",
    "if n_layers == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, (layer_name, emb) in enumerate(list(layer_embeddings.items())[:4]):\n",
    "    coords = viz.umap(emb)\n",
    "    viz.plot_scatter(coords, test_labels, title=f'UMAP: {layer_name}', method='UMAP', ax=axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probe accuracy at each layer\n",
    "# Use full dataset for more reliable probing\n",
    "all_data = list(train_data) + list(val_data) + list(test_data)\n",
    "all_labels = np.array([d.y.item() for d in all_data])\n",
    "\n",
    "extractor2 = LayerEmbeddingExtractor(model, device)\n",
    "extractor2.register_hooks()\n",
    "all_embeddings = extractor2.extract_graph_embeddings(all_data)\n",
    "extractor2.clear_hooks()\n",
    "\n",
    "prober = ProbingClassifier(seed=42)\n",
    "probe_results = prober.probe(all_embeddings, all_labels)\n",
    "probe_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probing accuracy across layers\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "layers = probe_results['layer'].tolist()\n",
    "acc = probe_results['accuracy_mean'].values\n",
    "acc_std = probe_results['accuracy_std'].values\n",
    "f1 = probe_results['f1_mean'].values\n",
    "f1_std = probe_results['f1_std'].values\n",
    "\n",
    "x = range(len(layers))\n",
    "ax.errorbar(x, acc, yerr=acc_std, label='Accuracy', marker='o', capsize=3, color=COLORS['primary'])\n",
    "ax.errorbar(x, f1, yerr=f1_std, label='F1', marker='s', capsize=3, color=COLORS['hallu'])\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(layers, rotation=45, ha='right')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Linear Probing: Where Does Class Separation Emerge?')\n",
    "ax.legend()\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Chance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"A sharp increase in probing accuracy identifies where the model 'commits' to its decision.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CKA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CKA within the model\n",
    "cka_matrix, layer_names = CKAAnalysis.compute_cka_matrix(all_embeddings)\n",
    "\n",
    "fig = heatmap(\n",
    "    cka_matrix, layer_names, layer_names,\n",
    "    title='CKA: Representation Similarity Across Layers',\n",
    "    cmap='viridis', center=None, fmt='.2f',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cosine Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within-class vs between-class similarity at each layer\n",
    "sim_results = []\n",
    "for layer_name, emb in all_embeddings.items():\n",
    "    sim = cosine_similarity_analysis(emb, all_labels)\n",
    "    sim['layer'] = layer_name\n",
    "    sim_results.append(sim)\n",
    "\n",
    "sim_df = pd.DataFrame(sim_results)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = range(len(sim_df))\n",
    "ax.plot(x, sim_df['within_class_sim'], 'o-', label='Within-class', color=COLORS['truth'])\n",
    "ax.plot(x, sim_df['between_class_sim'], 's-', label='Between-class', color=COLORS['hallu'])\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sim_df['layer'], rotation=45, ha='right')\n",
    "ax.set_ylabel('Cosine Similarity')\n",
    "ax.set_title('Within-Class vs Between-Class Similarity Across Layers')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSeparation ratio (within/between) should increase across layers:\")\n",
    "print(sim_df[['layer', 'separation_ratio']].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
