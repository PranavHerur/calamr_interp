{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6: Case Studies & Qualitative Analysis\n",
    "\n",
    "**Question:** Can we trace predictions back to interpretable concepts in the original text?\n",
    "\n",
    "This notebook:\n",
    "1. Selects 8 exemplar cases (2 TP, 2 TN, 2 FP, 2 FN) by confidence\n",
    "2. Visualizes bipartite alignment graphs with attribution overlays\n",
    "3. Maps important nodes/edges back to AMR concepts\n",
    "4. Generates explanation cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from calamr_interp.utils.data_loading import load_and_split\n",
    "from calamr_interp.utils.model_loading import create_model\n",
    "from calamr_interp.utils.visualization import setup_style\n",
    "from calamr_interp.phase4_attribution import GradientSaliency\n",
    "from calamr_interp.phase6_case_studies import (\n",
    "    CaseStudySelector,\n",
    "    AlignmentGraphVisualizer,\n",
    "    ExplanationGenerator,\n",
    ")\n",
    "\n",
    "setup_style()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model & Select Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data, val_data, test_data = load_and_split()\n",
    "test_list = list(test_data)\n",
    "print(f'Test: {len(test_list)} graphs')\n",
    "\n",
    "# Load model (update path as needed)\n",
    "model = create_model('EdgeAwareGAT')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Select exemplar cases\n",
    "selector = CaseStudySelector(model, device)\n",
    "cases = selector.select(test_list, n_per_category=2)\n",
    "\n",
    "for cat, items in cases.items():\n",
    "    print(f'\\n{cat}: {len(items)} cases')\n",
    "    for item in items:\n",
    "        print(f'  idx={item[\"index\"]}, prob={item[\"pred_prob\"]:.3f}, label={item[\"label\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradient saliency for selected cases\n",
    "saliency = GradientSaliency(model, device)\n",
    "\n",
    "all_attributions = {}\n",
    "for cat, items in cases.items():\n",
    "    for item in items:\n",
    "        idx = item['index']\n",
    "        attrs = saliency.attribute(item['data'])\n",
    "        all_attributions[idx] = attrs\n",
    "\n",
    "print(f'Computed attributions for {len(all_attributions)} cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization: Bipartite Alignment Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize each case\n",
    "visualizer = AlignmentGraphVisualizer()\n",
    "\n",
    "for cat in ['TP', 'TN', 'FP', 'FN']:\n",
    "    if cat not in cases or not cases[cat]:\n",
    "        print(f'No {cat} cases found')\n",
    "        continue\n",
    "    \n",
    "    for item in cases[cat]:\n",
    "        idx = item['index']\n",
    "        data = item['data']\n",
    "        attrs = all_attributions.get(idx, {})\n",
    "        \n",
    "        edge_imp = attrs.get('edge_saliency', None)\n",
    "        node_imp = attrs.get('node_saliency', None)\n",
    "        \n",
    "        title = f\"{cat}: idx={idx}, prob={item['pred_prob']:.3f}, true={'Hallu' if item['label']==1 else 'Truth'}\"\n",
    "        fig = visualizer.plot_bipartite(\n",
    "            data,\n",
    "            edge_importance=edge_imp,\n",
    "            node_importance=node_imp,\n",
    "            title=title,\n",
    "        )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explanation Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate explanation cards\n",
    "explainer = ExplanationGenerator(model, device)\n",
    "\n",
    "for cat in ['TP', 'FP']:\n",
    "    if cat not in cases or not cases[cat]:\n",
    "        continue\n",
    "    \n",
    "    item = cases[cat][0]  # Most confident\n",
    "    idx = item['index']\n",
    "    attrs = all_attributions.get(idx, {})\n",
    "    \n",
    "    card = explainer.generate_card(\n",
    "        data=item['data'],\n",
    "        pred_prob=item['pred_prob'],\n",
    "        label=item['label'],\n",
    "        edge_importance=attrs.get('edge_saliency'),\n",
    "        node_importance=attrs.get('node_saliency'),\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EXPLANATION CARD: {cat} (index={idx})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    pred = card['prediction']\n",
    "    print(f\"Predicted: {pred['predicted_label']} (prob={pred['probability']:.3f})\")\n",
    "    print(f\"Actual:    {pred['true_label']}\")\n",
    "    print(f\"Correct:   {pred['correct']}\")\n",
    "    \n",
    "    stats = card['graph_stats']\n",
    "    print(f\"\\nGraph: {stats['n_nodes']} nodes, {stats['n_edges']} edges\")\n",
    "    print(f\"  Source: {stats['n_source_nodes']}, Summary: {stats['n_summary_nodes']}\")\n",
    "    print(f\"  Alignment edges: {stats['n_alignment_edges']}\")\n",
    "    print(f\"  Mean alignment flow: {stats['mean_alignment_flow']:.3f}\")\n",
    "    print(f\"  Max alignment flow:  {stats['max_alignment_flow']:.3f}\")\n",
    "    \n",
    "    if 'top_edges' in card:\n",
    "        print(f\"\\nTop 5 important edges:\")\n",
    "        for e in card['top_edges'][:5]:\n",
    "            edge_type = 'ALIGN' if e['is_alignment'] else 'INTRL'\n",
    "            print(f\"  [{edge_type}] {e['source']}->{e['target']} imp={e['importance']:.4f} flow={e['flow']:.3f}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Key Interpretation ===\")\n",
    "print(\"Look for patterns like:\")\n",
    "print(\"- TP hallucinations: summary nodes with weak/no alignment, low flow values\")\n",
    "print(\"- FP errors: graphs where strong alignment exists but model is confused\")\n",
    "print(\"- FN misses: hallucination graphs that look structurally similar to truth\")\n",
    "print(\"\\nThe most interpretable findings will come from combining:\")\n",
    "print(\"1. Attribution overlays (which edges/nodes matter)\")\n",
    "print(\"2. Text mapping (what AMR concepts these correspond to)\")\n",
    "print(\"3. Flow values (how strongly aligned are the concepts)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
